{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO81Wd+zfgcXriivl+hd4NF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanshu-Naik/Gen_AI/blob/main/GlovWo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove Word Embedding in NLP\n"
      ],
      "metadata": {
        "id": "pm9QG5cC7U1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing Libraries\n",
        "\n",
        "We will be importing necessary libraries to handle text processing and numerical operations.\n",
        "\n",
        "Tokenizer and pad_sequences from tensorflow.keras.preprocessing.text help us tokenize the text and manage sequences of tokens, respectively.\n",
        "\n",
        "numpy is used for handling numerical operations, especially creating and manipulating arrays like the embedding matrix.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aTkWPN-V7hAK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTCxZUheu1wf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Creating Vocabulary\n",
        "\n",
        "We will be defining a list of words (texts) that we want to use for building a vocabulary. These words represent our small sample text corpus that the tokenizer will later process.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NFIBpGym_FUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = ['text', 'the', 'leader', 'prime', 'natural', 'language']"
      ],
      "metadata": {
        "id": "H2PH4fd2_DGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Initializing and Fitting the Tokenizer\n",
        "\n",
        "We will be initializing the Tokenizer object and fitting it on the texts corpus to create a dictionary of words and their corresponding integer indices. The tokenizer will break the words into unique tokens and assign each token an integer ID.\n",
        "\n",
        "The fit_on_texts function processes the provided corpus and generates the word-to-index mapping.\n",
        "\n",
        "tokenizer.word_index gives the dictionary that maps each word to its corresponding index."
      ],
      "metadata": {
        "id": "hatHJxCu_NdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "print(\"Number of unique words in dictionary = \", len(tokenizer.word_index))\n",
        "print(\"Dictionary is = \" , tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_0UtLmo_VO8",
        "outputId": "0fa32e0b-3c60-402d-b3dd-bffc7ce2b434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in dictionary =  6\n",
            "Dictionary is =  {'text': 1, 'the': 2, 'leader': 3, 'prime': 4, 'natural': 5, 'language': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Defining a Function to Create Embedding Matrix\n",
        "\n",
        "We will be defining the function embedding_for_vocab that loads pre-trained GloVe word vectors and creates an embedding matrix for the vocabulary.\n",
        "\n",
        "filepath: Path to the GloVe file.\n",
        "\n",
        "word_index: The dictionary created by the tokenizer, mapping words to indices.\n",
        "\n",
        "embedding_dim: The dimensionality of the word vectors (e.g., 50-dimensional vectors).\n",
        "\n",
        "Inside the function:\n",
        "\n",
        "We initialize a matrix of zeros with shape (vocab_size, embedding_dim) where vocab_size is the number of words plus one (to account for the padding token).\n",
        "\n",
        "We read the GloVe file line by line and match the word to the tokenizer's word index, copying the corresponding word vector to the embedding matrix.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MQVuMFCLAhYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_for_vocab(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    with open(filepath, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "TxJnqaNeAw0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Downloading GloVe File\n",
        "\n",
        "We will be downloading the GloVe dataset from Stanford's NLP repository. This dataset contains pre-trained word embeddings, and we will be specifically using the 50-dimensional embeddings (glove.6B.50d.txt).\n",
        "\n",
        "!wget is used to download the file.\n",
        "\n",
        "!unzip is used to extract the zipped GloVe file.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6RjAKBPzBECs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgUvCaVxBIz6",
        "outputId": "464dc13d-efd7-4e3b-ed25-2908212dc05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-25 19:38:05--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.06MB/s    in 2m 39s  \n",
            "\n",
            "2025-12-25 19:40:44 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Loading GloVe Embeddings and Creating a Matrix\n",
        "\n",
        "We will be specifying the embedding dimension (50 in this case, matching the GloVe file) and providing the path to the GloVe file. We then call the previously defined function embedding_for_vocab to load the GloVe embeddings and generate the embedding matrix for our vocabulary.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rOKJXkhzCW__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.terminal.embed import embed\n",
        "embedding_dim = 50\n",
        "embedding_matrix = embedding_for_vocab('glove.6B.50d.txt', tokenizer.word_index, embedding_dim)"
      ],
      "metadata": {
        "id": "kISoqxWoCTA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Accessing Embedding Vector for a Word\n",
        "\n",
        "We will be accessing the embedding vector for a specific word in the tokenizer’s index. In this case, we're accessing the vector for the word with index 1, which corresponds to the word \"text\" in the vocabulary.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WdzvqbacCkGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_word_index = 1\n",
        "print(\"Dense vector for word with index 1=> \", embedding_matrix[first_word_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucy8DxrqCnfz",
        "outputId": "2d2c29e3-94f7-4e00-c2b0-ad11d71993db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense vector for word with index 1=>  [ 0.32615     0.36686    -0.0074905  -0.37553     0.66715002  0.21646\n",
            " -0.19801    -1.10010004 -0.42221001  0.10574    -0.31292     0.50953001\n",
            "  0.55774999  0.12019     0.31441    -0.25042999 -1.06369996 -1.32130003\n",
            "  0.87797999 -0.24627     0.27379    -0.51091999  0.49324     0.52243\n",
            "  1.16359997 -0.75322998 -0.48052999 -0.11259    -0.54595    -0.83920997\n",
            "  2.98250008 -1.19159997 -0.51958001 -0.39365    -0.1419     -0.026977\n",
            "  0.66295999  0.16574    -1.1681      0.14443     1.63049996 -0.17216\n",
            " -0.17436001 -0.01049    -0.17794     0.93076003  1.0381      0.94265997\n",
            " -0.14805    -0.61109   ]\n"
          ]
        }
      ]
    }
  ]
}